import{j as e}from"./index-vpKu_s3s.js";function t(){return e.jsxs("main",{className:"max-w-3xl mx-auto px-6 py-12 text-gray-800",children:[e.jsx("h1",{className:"text-4xl font-bold mb-2",children:"Finding the Needle in the Haystack: Similarity Search & Grouping"}),e.jsx("p",{className:"text-gray-500 mb-8",children:"Posted on 2026-02-17"}),e.jsx("p",{className:"mb-6",children:"In the previous entry, I introduced a persistent hash cache to stop re-processing the same files over and over. With that foundation in place, I could finally tackle the core problem that started this whole project:"}),e.jsx("p",{className:"mb-8 font-semibold",children:"My photo library is a mess of near-duplicates, resized copies, and slightly edited versions."}),e.jsxs("p",{className:"mb-6",children:["I currently have over 50,000 photos scattered across multiple drives. Deleting exact duplicates (same byte content) cleans up about 10% of them. The rest? They require ",e.jsx("strong",{children:"visual similarity"})," matching."]}),e.jsx("h2",{className:"text-2xl font-semibold mb-4",children:"Pipeline Architecture: Pragmatism over Abstraction"}),e.jsxs("p",{className:"mb-6",children:["As I started building the similarity engine, I ran into a wall with my original pipeline design. I had tried to make everything a generic",e.jsx("code",{children:"Stage"})," class that could be chained together endlessly."]}),e.jsx("p",{className:"mb-6",children:"It sounded great in theory. In practice, it was a nightmare."}),e.jsxs("p",{className:"mb-6",children:["Some stages need one input and one output. Others (like the SimilarityEngine) need to consume ",e.jsx("em",{children:"all"})," inputs before producing a single comprehensive output. Some need to talk to the database; others are pure CPU work."]}),e.jsx("p",{className:"mb-6",children:"I found myself writing more code to satisfy the abstraction than to solve the actual problem. So, I took a step back."}),e.jsxs("p",{className:"mb-6",children:["Usage of ",e.jsx("code",{children:"PipelineController"})," remains — it’s still the conductor. But instead of forcing every stage to look identical, I moved to concrete, purpose-built classes for each step."]}),e.jsxs("ul",{className:"list-disc list-inside mb-8 space-y-1",children:[e.jsxs("li",{children:[e.jsx("strong",{children:"Scanner"}),": Finds files."]}),e.jsxs("li",{children:[e.jsx("strong",{children:"HashWorker"}),": Computes hashes."]}),e.jsxs("li",{children:[e.jsx("strong",{children:"SimilarityEngine"}),": Groups them."]})]}),e.jsx("p",{className:"mb-8",children:"They share common data structures, but they don’t share a forced common interface. This made the code simpler, easier to debug, and much easier to extend."}),e.jsx("h2",{className:"text-2xl font-semibold mb-4",children:"The Similarity Engine"}),e.jsx("p",{className:"mb-6",children:"With the pipeline unblocked, I implemented the grouping logic. It relies on a multi-pass approach."}),e.jsx("h3",{className:"text-xl font-semibold mb-2",children:"Pass 1: Exact Matches"}),e.jsx("p",{className:"mb-6",children:"First, we group files by SHA-256 hash. These are byte-for-byte identical. This is fast and safe."}),e.jsx("h3",{className:"text-xl font-semibold mb-2",children:"Pass 2: Perceptual Grouping"}),e.jsxs("p",{className:"mb-6",children:["For the remaining images, we need to determine if they ",e.jsx("em",{children:"look"})," the same. I didn't want to rely on a single algorithm, so I implemented a weighted scoring system."]}),e.jsx("pre",{className:"bg-gray-900 text-green-300 text-sm p-4 rounded-lg mb-8 overflow-x-auto text-left font-mono whitespace-pre leading-relaxed",children:`struct Config {
    double strongThreshold = 0.90;
    
    // Weighted components
    double pHashWeight = 0.45;  // Perceptual Hash
    double dHashWeight = 0.25;  // Difference Hash
    double aHashWeight = 0.20;  // Average Hash
    double ratioWeight = 0.10;  // Aspect Ratio
};`}),e.jsx("p",{className:"mb-8",children:"By combining pHash (structure), dHash (gradients), and aHash (color/brightness), plus a check on aspect ratio, we get a robust similarity score. If the weighted score exceeds 90%, the images are grouped together."}),e.jsx("h2",{className:"text-2xl font-semibold mb-4",children:"UI: Dark Mode & Previews"}),e.jsx("p",{className:"mb-6",children:"Finally, I needed a way to verify these groups. Visual inspection is the only way to trust a tool like this."}),e.jsxs("p",{className:"mb-6",children:["I built a ",e.jsx("code",{children:"GroupWidget"}),' that displays the "representative" image (best quality) alongside all its matches. I also added a dedicated ',e.jsx("code",{children:"PreviewPane"})," to inspect details side-by-side."]}),e.jsxs("p",{className:"mb-6",children:["And, of course, I finally added ",e.jsx("strong",{children:"Dark Mode"}),". Because if you're going to stare at a photo deduplication tool at 2 AM, it might as well be easy on the eyes."]}),e.jsx("div",{className:"bg-gray-800 rounded-lg h-64 flex items-center justify-center text-gray-400 mb-8",children:"(Screenshot of the new Dark Mode Group Preview)"}),e.jsx("h2",{className:"text-2xl font-semibold mb-4",children:"What’s Next?"}),e.jsxs("p",{className:"mb-8",children:["Now that grouping works, the next step is ",e.jsx("strong",{children:"Action"}),". I need to build the UI for efficiently selecting which images to keep and which to delete within these groups."]})]})}export{t as default};
